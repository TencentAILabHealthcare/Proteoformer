{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## π-Proteoformer Variant PTM Effect Prediction \n",
    "\n",
    "This notebook demonstrates how to use the pre-trained π-Proteoformer model and fine-tuned classifier for predicting PTM effect changes due to variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add the proteoformer package to path\n",
    "PROJECT_ROOT = Path(\"your/project/root\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"proteoformer_codebase\" / \"pi-Proteoformer\" / \"src\"))\n",
    "\n",
    "# Import Proteoformer components\n",
    "from proteoformer.net import ProteoformerForEmbedding\n",
    "from proteoformer.tokenization import ProteoformerTokenizer\n",
    "from proteoformer.models import VariantPTMClassifier\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Paths configuration\n",
    "PRETRAINED_MODEL_PATH = 'checkpoint-197000'\n",
    "\n",
    "# Path to the fine-tuned Variant PTM classifier checkpoint\n",
    "VARIANT_PTM_CHECKPOINT_PATH = 'indirect_model.pt'\n",
    "\n",
    "\n",
    "# Maximum sequence length for tokenization\n",
    "MAX_LENGTH = 1024\n",
    "\n",
    "# Hidden dimension for the classifier (must match training)\n",
    "HIDDEN_DIM = 512\n",
    "\n",
    "# Dropout rate for the classifier\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply mean pooling over sequence length (excluding padding).\n",
    "    \n",
    "    Args:\n",
    "        hidden_states: Hidden states from model (batch_size, seq_len, hidden_size)\n",
    "        attention_mask: Attention mask (batch_size, seq_len)\n",
    "    \n",
    "    Returns:\n",
    "        Pooled embeddings (batch_size, hidden_size)\n",
    "    \"\"\"\n",
    "    mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "    sum_embeddings = torch.sum(hidden_states * mask_expanded, dim=1)\n",
    "    sum_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def extract_embeddings(\n",
    "    model: ProteoformerForEmbedding,\n",
    "    tokenizer: ProteoformerTokenizer,\n",
    "    peptides: List[str],\n",
    "    device: torch.device,\n",
    "    batch_size: int = 8,\n",
    "    max_length: int = 1024\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract embeddings for a list of peptide sequences.\n",
    "    \n",
    "    Args:\n",
    "        model: Pretrained ProteoformerForEmbedding model\n",
    "        tokenizer: ProteoformerTokenizer\n",
    "        peptides: List of peptide sequences\n",
    "        device: Device to run inference on\n",
    "        batch_size: Batch size for inference\n",
    "        max_length: Maximum sequence length for model input\n",
    "    \n",
    "    Returns:\n",
    "        Tensor of embeddings (num_peptides, hidden_size)\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(peptides), batch_size):\n",
    "            batch_peptides = peptides[i:i + batch_size]\n",
    "            \n",
    "            # Tokenize batch\n",
    "            encoded = tokenizer(\n",
    "                batch_peptides,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\",\n",
    "                add_special_tokens=False\n",
    "            )\n",
    "            \n",
    "            # Move to device\n",
    "            input_ids = encoded['input_ids'].to(device)\n",
    "            attention_mask = encoded['attention_mask'].to(device)\n",
    "            \n",
    "            # Get embeddings from model\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            # Extract last hidden state\n",
    "            hidden_states = outputs.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
    "            \n",
    "            # Apply mean pooling\n",
    "            batch_embeddings = mean_pooling(hidden_states, attention_mask)\n",
    "            all_embeddings.append(batch_embeddings.cpu())\n",
    "    \n",
    "    # Concatenate all embeddings\n",
    "    embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Model Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(\n",
    "    proteoformer_checkpoint: str,\n",
    "    variant_ptm_checkpoint: str,\n",
    "    device: torch.device,\n",
    "    hidden_dim: int = 512,\n",
    "    dropout: float = 0.3\n",
    ") -> Tuple[ProteoformerForEmbedding, VariantPTMClassifier, ProteoformerTokenizer]:\n",
    "    \"\"\"\n",
    "    Load the complete Variant PTM effect prediction model.\n",
    "    \n",
    "    This loads:\n",
    "    1. Proteoformer model for encoding protein sequences\n",
    "    2. VariantPTMClassifier for predicting PTM effect change\n",
    "    3. Tokenizer for sequence tokenization\n",
    "    \n",
    "    Args:\n",
    "        proteoformer_checkpoint: Path to Proteoformer model checkpoint\n",
    "        variant_ptm_checkpoint: Path to fine-tuned VariantPTM classifier checkpoint\n",
    "        device: Torch device to load models on\n",
    "        hidden_dim: Hidden dimension for the classifier\n",
    "        dropout: Dropout rate for the classifier\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (proteoformer_model, variant_ptm_classifier, tokenizer)\n",
    "    \"\"\"\n",
    "    # print(f\"Loading Proteoformer from {proteoformer_checkpoint}...\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = ProteoformerTokenizer.from_pretrained(proteoformer_checkpoint)\n",
    "    \n",
    "    # Load Proteoformer backbone model\n",
    "    proteoformer_model = ProteoformerForEmbedding.from_pretrained(proteoformer_checkpoint)\n",
    "    proteoformer_model = proteoformer_model.to(device)\n",
    "    proteoformer_model.eval()\n",
    "    \n",
    "    # Get embedding dimension from model config\n",
    "    embedding_dim = proteoformer_model.config.hidden_size\n",
    "    print(f\"  - Model hidden size: {embedding_dim}\")\n",
    "    print(f\"  - Number of layers: {proteoformer_model.config.num_hidden_layers}\")\n",
    "    \n",
    "    # Create the Variant PTM classifier\n",
    "    # print(f\"Loading VariantPTM classifier from {variant_ptm_checkpoint}...\")\n",
    "    variant_ptm_classifier = VariantPTMClassifier(\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    \n",
    "    # Load the fine-tuned checkpoint\n",
    "    checkpoint = torch.load(variant_ptm_checkpoint, map_location=device)\n",
    "    variant_ptm_classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "    variant_ptm_classifier = variant_ptm_classifier.to(device)\n",
    "    variant_ptm_classifier.eval()\n",
    "    \n",
    "    print(\"Models loaded successfully!\")\n",
    "    return proteoformer_model, variant_ptm_classifier, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_pair(\n",
    "    proteoformer_model: ProteoformerForEmbedding,\n",
    "    variant_ptm_classifier: VariantPTMClassifier,\n",
    "    tokenizer: ProteoformerTokenizer,\n",
    "    wt_peptide: str,\n",
    "    mt_peptide: str,\n",
    "    device: torch.device,\n",
    "    max_length: int = 1024,\n",
    "    threshold: float = 0.5\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Predict PTM effect change for a single WT/MT peptide pair.\n",
    "    \n",
    "    This function:\n",
    "    1. Encodes WT and MT sequences using Proteoformer\n",
    "    2. Computes delta embeddings: ΔE = E_MT - E_WT\n",
    "    3. Predicts PTM effect change using the classifier\n",
    "    \n",
    "    Args:\n",
    "        proteoformer_model: Loaded Proteoformer model\n",
    "        variant_ptm_classifier: Loaded VariantPTM classifier\n",
    "        tokenizer: Loaded tokenizer\n",
    "        wt_peptide: Wild-type peptide sequence\n",
    "        mt_peptide: Mutant peptide sequence\n",
    "        device: Torch device\n",
    "        max_length: Maximum sequence length\n",
    "        threshold: Classification threshold (default 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - probability: Probability of Decrease effect (0-1)\n",
    "        - prediction: Binary prediction (0=Increase, 1=Decrease)\n",
    "        - label: Human-readable prediction label\n",
    "    \"\"\"\n",
    "    proteoformer_model.eval()\n",
    "    variant_ptm_classifier.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Extract WT embedding\n",
    "        wt_embedding = extract_embeddings(\n",
    "            model=proteoformer_model,\n",
    "            tokenizer=tokenizer,\n",
    "            peptides=[wt_peptide],\n",
    "            device=device,\n",
    "            batch_size=1,\n",
    "            max_length=max_length\n",
    "        )  # (1, hidden_dim)\n",
    "        \n",
    "        # Extract MT embedding\n",
    "        mt_embedding = extract_embeddings(\n",
    "            model=proteoformer_model,\n",
    "            tokenizer=tokenizer,\n",
    "            peptides=[mt_peptide],\n",
    "            device=device,\n",
    "            batch_size=1,\n",
    "            max_length=max_length\n",
    "        )  # (1, hidden_dim)\n",
    "        \n",
    "        # Compute delta embedding: ΔE = E_MT - E_WT\n",
    "        delta_embedding = mt_embedding - wt_embedding\n",
    "        delta_embedding = delta_embedding.to(device)\n",
    "        \n",
    "        # Predict PTM effect change\n",
    "        logits = variant_ptm_classifier(delta_embedding)\n",
    "        probability = torch.sigmoid(logits).item()\n",
    "        prediction = 1 if probability >= threshold else 0\n",
    "    \n",
    "    return {\n",
    "        'probability': probability,\n",
    "        'prediction': prediction,\n",
    "        'label': 'Decrease' if prediction == 1 else 'Increase'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Loading π-Proteoformer and VariantPTM Classifier\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type proteoformer2 to instantiate a model of type proteoformer. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Model hidden size: 1280\n",
      "  - Number of layers: 24\n",
      "Models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Loading π-Proteoformer and VariantPTM Classifier\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "proteoformer_model, variant_ptm_classifier, tokenizer = load_models(\n",
    "    proteoformer_checkpoint=PRETRAINED_MODEL_PATH,\n",
    "    variant_ptm_checkpoint=VARIANT_PTM_CHECKPOINT_PATH,\n",
    "    device=device,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Single Pair Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {\n",
    "    \"PTM\": \"Sumoylation\",\n",
    "    \"Gene_symbol\": \"AKT1\",\n",
    "    \"UniProt_ID\": \"P31749\",\n",
    "    \"AA_Ref\": \"E\",\n",
    "    \"AA_Pos\": 278,\n",
    "    \"AA_Var\": \"Q\",\n",
    "    \"Affected_site_pos\": 276,\n",
    "    \"diff_pos\": 2,\n",
    "    \"Effect\": \"Decrease\",  # Ground truth\n",
    "    \"WT_pep\": \"NVVYRDLKLENLMLD\",\n",
    "    \"MT_pep\": \"NVVYRDLKLQNLMLD\",\n",
    "    \"Impact_Type\": \"Indirect\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Results:\n",
      "  - Predicted Effect: Decrease\n",
      "  - Correct: ✓\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "result = predict_single_pair(\n",
    "    proteoformer_model=proteoformer_model,\n",
    "    variant_ptm_classifier=variant_ptm_classifier,\n",
    "    tokenizer=tokenizer,\n",
    "    wt_peptide=example['WT_pep'],\n",
    "    mt_peptide=example['MT_pep'],\n",
    "    device=device,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "print(f\"\\nPrediction Results:\")\n",
    "print(f\"  - Predicted Effect: {result['label']}\")\n",
    "print(f\"  - Correct: {'✓' if result['label'] == example['Effect'] else '✗'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi_proteoform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
