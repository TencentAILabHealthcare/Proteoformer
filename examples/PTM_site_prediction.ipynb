{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ï€-Proteoformer PTM Sites Prediction \n",
    "\n",
    "This notebook demonstrates how to use the pre-trained $\\pi$-Proteoformer model for predicting phosphorylation sites (S/T)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the proteoformer package to path\n",
    "PROJECT_ROOT = Path(\"your/project/root\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT  / \"pi-Proteoformer\" / \"src\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import Proteoformer components\n",
    "from proteoformer.net import ProteoformerForEmbedding\n",
    "from proteoformer.tokenization import ProteoformerTokenizer\n",
    "from proteoformer.models import ProteoformerClassifier\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Paths configuration\n",
    "PRETRAINED_MODEL_PATH = '/pretrain_stage2/checkpoint-197000'\n",
    "\n",
    "# Path to the fine-tuned phosphorylation S/T checkpoint\n",
    "PTM_CHECKPOINT_PATH = 'phosphorylation_st_best_checkpoint_proteoformer.pt'\n",
    "\n",
    "# Example test data path (optional)\n",
    "TEST_DATA_PATH = '/data/phosphorylation_st_test_data_filtered.tsv'\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Model parameters\n",
    "MAX_LENGTH = 31  # Default sequence length (15 residues on each side + center)\n",
    "HIDDEN_SIZE = 512  # CNN classifier hidden size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ptm_predictor(pretrained_path, checkpoint_path, device, hidden_size=512):\n",
    "    \"\"\"\n",
    "    Load the complete PTM prediction model with pre-trained weights.\n",
    "    \n",
    "    Args:\n",
    "        pretrained_path: Path to the pre-trained Proteoformer2 model\n",
    "        checkpoint_path: Path to the fine-tuned PTM classifier checkpoint\n",
    "        device: Torch device to load the model on\n",
    "        hidden_size: Hidden size for the CNN classifier\n",
    "        \n",
    "    Returns:\n",
    "        model: Loaded ProteoformerClassifier model\n",
    "        tokenizer: Loaded ProteoformerTokenizer\n",
    "    \"\"\"\n",
    "    # print(f\"Loading tokenizer from {pretrained_path}...\")\n",
    "    tokenizer = ProteoformerTokenizer.from_pretrained(str(pretrained_path))\n",
    "    \n",
    "    # print(f\"Loading Proteoformer2 backbone model from {pretrained_path}...\")\n",
    "    proteoformer_model = ProteoformerForEmbedding.from_pretrained(str(pretrained_path))\n",
    "    \n",
    "    # Get embedding dimension from model config\n",
    "    embedding_dim = proteoformer_model.config.hidden_size\n",
    "    print(f\"Model hidden size: {embedding_dim}\")\n",
    "    print(f\"Number of layers: {proteoformer_model.config.num_hidden_layers}\")\n",
    "    \n",
    "    # Create the classifier model\n",
    "    print(\"Creating ProteoformerClassifier...\")\n",
    "    model = ProteoformerClassifier(proteoformer_model, embedding_dim, hidden_size)\n",
    "    \n",
    "    # Load the fine-tuned checkpoint\n",
    "    # print(f\"Loading fine-tuned checkpoint from {checkpoint_path}...\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Load state dict\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Print checkpoint information\n",
    "    if 'metrics' in checkpoint:\n",
    "        metrics = checkpoint['metrics']\n",
    "        print(f\"Checkpoint metrics:\")\n",
    "        print(f\"  - MCC: {metrics.get('MCC', 'N/A')}\")\n",
    "        print(f\"  - AUC-ROC: {metrics.get('AUC_ROC', 'N/A')}\")\n",
    "        print(f\"  - F1 Score: {metrics.get('F1_Score', 'N/A')}\")\n",
    "    \n",
    "    # Move to device and set to eval mode\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"Model loaded successfully!\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type proteoformer2 to instantiate a model of type proteoformer. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model hidden size: 1280\n",
      "Number of layers: 24\n",
      "Creating ProteoformerClassifier...\n",
      "Checkpoint metrics:\n",
      "  - MCC: 0.5546809420962806\n",
      "  - AUC-ROC: 0.882858683222495\n",
      "  - F1 Score: 0.6237148732008225\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model, tokenizer = load_ptm_predictor(\n",
    "    pretrained_path=PRETRAINED_MODEL_PATH,\n",
    "    checkpoint_path=PTM_CHECKPOINT_PATH,\n",
    "    device=DEVICE,\n",
    "    hidden_size=HIDDEN_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_sequence(model, tokenizer, sequence, device, max_length=31, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict phosphorylation probability for a single sequence window.\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded ProteoformerClassifier model\n",
    "        tokenizer: Loaded ProteoformerTokenizer\n",
    "        sequence: Protein sequence window (e.g., 31 amino acids with S/T at center)\n",
    "        device: Torch device\n",
    "        max_length: Maximum sequence length for tokenization\n",
    "        threshold: Classification threshold (default 0.5)\n",
    "        \n",
    "    Returns:\n",
    "        probability: Phosphorylation probability (0-1)\n",
    "        prediction: Binary prediction (0 or 1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Tokenize the sequence\n",
    "        enc = tokenizer(\n",
    "            sequence, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "        \n",
    "        input_ids = enc[\"input_ids\"].to(device)\n",
    "        attention_mask = enc.get(\"attention_mask\", None)\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.to(device)\n",
    "        \n",
    "        # Get prediction probability\n",
    "        probability = model(input_ids, attention_mask, return_logits=False)\n",
    "        probability = probability.item()\n",
    "        \n",
    "        # Get binary prediction\n",
    "        prediction = 1 if probability > threshold else 0\n",
    "        \n",
    "    return probability, prediction\n",
    "\n",
    "\n",
    "def predict_batch(model, tokenizer, sequences, device, max_length=31, batch_size=32, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict phosphorylation probabilities for a batch of sequences.\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded ProteoformerClassifier model\n",
    "        tokenizer: Loaded ProteoformerTokenizer\n",
    "        sequences: List of protein sequence windows\n",
    "        device: Torch device\n",
    "        max_length: Maximum sequence length for tokenization\n",
    "        batch_size: Batch size for inference\n",
    "        threshold: Classification threshold (default 0.5)\n",
    "        \n",
    "    Returns:\n",
    "        probabilities: List of phosphorylation probabilities\n",
    "        predictions: List of binary predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(sequences), batch_size), desc=\"Predicting\"):\n",
    "        batch_seqs = sequences[i:i+batch_size]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Tokenize batch\n",
    "            enc = tokenizer(\n",
    "                batch_seqs,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                add_special_tokens=False\n",
    "            )\n",
    "            \n",
    "            input_ids = enc[\"input_ids\"].to(device)\n",
    "            attention_mask = enc.get(\"attention_mask\", None)\n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask.to(device)\n",
    "            \n",
    "            # Get prediction probabilities\n",
    "            probs = model(input_ids, attention_mask, return_logits=False)\n",
    "            probs = probs.cpu().numpy()\n",
    "            \n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_preds.extend((probs > threshold).astype(int).tolist())\n",
    "    \n",
    "    return all_probs, all_preds\n",
    "\n",
    "\n",
    "def extract_site_windows(protein_sequence, window_size=16, target_residues=['S', 'T']):\n",
    "    \"\"\"\n",
    "    Extract sequence windows for all potential phosphorylation sites in a protein.\n",
    "    \n",
    "    Args:\n",
    "        protein_sequence: Full protein sequence\n",
    "        window_size: Number of residues on each side of the target site (default 16)\n",
    "        target_residues: List of target residues to extract windows for (default ['S', 'T'])\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples: (position, residue, sequence_window)\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    seq_len = len(protein_sequence)\n",
    "    \n",
    "    for i, residue in enumerate(protein_sequence):\n",
    "        if residue in target_residues:\n",
    "            # Extract window\n",
    "            start = max(0, i - window_size)\n",
    "            end = min(seq_len, i + window_size + 1)\n",
    "            \n",
    "            # Pad if necessary\n",
    "            left_pad = window_size - (i - start)\n",
    "            right_pad = window_size - (end - i - 1)\n",
    "            \n",
    "            window = 'X' * left_pad + protein_sequence[start:end] + 'X' * right_pad\n",
    "            \n",
    "            windows.append((i + 1, residue, window))  # Position is 1-based\n",
    "    \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example: Single Sequence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single sequence prediction examples:\n",
      "============================================================\n",
      "\n",
      "Sequence: SQVAIEALSAMPTVRSFANEEGEAQKFREKL\n",
      "Center residue: S (position 16)\n",
      "Phosphorylation probability: 0.9241\n",
      "Prediction: Phosphorylated\n",
      "\n",
      "Sequence: LEFAKENRKCQEQAVSPKVDDQCGNSSSIPF\n",
      "Center residue: S (position 16)\n",
      "Phosphorylation probability: 0.8579\n",
      "Prediction: Phosphorylated\n",
      "\n",
      "Sequence: GQHETGGSPSKQQMRSVISVTSALKEVGVDS\n",
      "Center residue: S (position 16)\n",
      "Phosphorylation probability: 0.6696\n",
      "Prediction: Phosphorylated\n"
     ]
    }
   ],
   "source": [
    "# Example sequence windows (33 amino acids with S/T at center position)\n",
    "# These are example phosphorylation site sequences from the test dataset\n",
    "\n",
    "example_sequences = [\n",
    "    # Positive examples (known phosphorylation sites)\n",
    "    \"SQVAIEALSAMPTVRSFANEEGEAQKFREKL\",  # S at position 16\n",
    "    \"LEFAKENRKCQEQAVSPKVDDQCGNSSSIPF\",  # T at position 16\n",
    "    \"GQHETGGSPSKQQMRSVISVTSALKEVGVDS\",  # S at position 16\n",
    "    \n",
    "    # You can add your own sequences here\n",
    "]\n",
    "\n",
    "print(\"Single sequence prediction examples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for seq in example_sequences:\n",
    "    prob, pred = predict_single_sequence(model, tokenizer, seq, DEVICE)\n",
    "    center_pos = len(seq) // 2\n",
    "    center_residue = seq[center_pos]\n",
    "    \n",
    "    print(f\"\\nSequence: {seq}\")\n",
    "    print(f\"Center residue: {center_residue} (position {center_pos + 1})\")\n",
    "    print(f\"Phosphorylation probability: {prob:.4f}\")\n",
    "    print(f\"Prediction: {'Phosphorylated' if pred == 1 else 'Not phosphorylated'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi_proteoform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
